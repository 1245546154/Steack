集群架构：故障转移域  

c1  jdk    zook   datanode    hadoop	
c2  jdk    zook   datanode    hadoop	
c3  jdk    zook   datanode    hadoop	
c4  jdk       namedate        hadoop	
c5  jdk       namedate        hadoop	
c6  jdk       yarn            hadoop	



大数据是收集、整理、处理大容量数据集，并从中获得结果的技术总称。


hadoop是最受欢迎的在internet上对搜索关键字进行内容分类的工具，但他也可以解决许多的极大伸缩性的问题。

例如：如果想要grep一个10TB的巨型文件，那么就可以使用hadoop采用并行执行机制，因此能大大提高效率。

Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为了海量的数据提供了计算。

MapReduce功能实现了将单个任务打碎，并且将碎片任务MAP发送到多个节点上，之后再以单个数据集的形式加载（Reduce）到数据仓库里。

高可靠性：Hadoop按位存储和未处理数据的能力
高扩展性：Hadoop是在可用的计算机集群中分配数据并完成计算任务的，这些集群可以扩展到数以千计的节点中。
高容错性：Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。
低成本：  Happo开源，项目的成本因此会大大降低。
高效性：  Hadoop能够在节点之间动态的移动数据，并保证各个节点的动态平衡，因此处理速度非常快。


yarn：调度器   
yarn：是hadoop2.0新增加的一个子项目，为了弥补hadoop1.0的扩展性 


1、大数据文件，非常适合上TB级别的大文件或者一堆大数据文件的存储，如果文件只有几个G甚至更小就没啥意思了。

2、文件分块存储，HDFS会将一个完整的大文件平均分块存储到不同计算节点上，它的意义在于读取文件时可以同时从多个计算节点上读取不同区块的文件，多主机读取比单主机读取效率要高得多。

3、流式数据访问，一次写入多次读写，这种模式跟传统文件不同，它不支持动态改变文件内容，而是要求让文件一次写入就不做变化，要变化也只能在文件末添加内容。